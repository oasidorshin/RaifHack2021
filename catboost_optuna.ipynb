{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data import preprocess_data, postprocessing\n",
    "from func import deviation_metric_one_sample, get_timestamp\n",
    "\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c2ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_search = False\n",
    "training = False\n",
    "inference = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5070038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom eval metric for CatBoost\n",
    "# Based on https://catboost.ai/en/docs/concepts/python-usages-examples\n",
    "class UserDefinedMetric(object):\n",
    "    def is_max_optimal(self):\n",
    "        # Returns whether great values of metric are better\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        # approxes is a list of indexed containers\n",
    "        # (containers with only __len__ and __getitem__ defined),\n",
    "        # one container per approx dimension.\n",
    "        # Each container contains floats.\n",
    "        # weight is a one dimensional indexed container.\n",
    "        # target is a one dimensional indexed container.\n",
    "\n",
    "        # weight parameter can be None.\n",
    "        # Returns pair (error, weights sum)\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "\n",
    "        approx = approxes[0]\n",
    "\n",
    "        error_sum = 0.0\n",
    "        weight_sum = 0.0\n",
    "\n",
    "        for i in range(len(approx)):\n",
    "            w = 1.0 if weight is None else weight[i]\n",
    "            weight_sum += w\n",
    "            error_sum += w * deviation_metric_one_sample(np.expm1(target[i]), np.expm1(approx[i])) # expm1 because using log1p in loss\n",
    "\n",
    "        return error_sum, weight_sum\n",
    "\n",
    "    def get_final_error(self, error, weight):\n",
    "        # Returns final value of metric based on error and weight\n",
    "        return error / (weight + 1e-38)\n",
    "\n",
    "# Catboost with custom metric is spamming numba warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de01e524",
   "metadata": {},
   "source": [
    "## Optuna hyper search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f320eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    train = pd.read_csv('data/train.csv')\n",
    "    test = pd.read_csv('data/test.csv')\n",
    "    eps = trial.suggest_loguniform('eps', 0.01, 0.05) # dbscan param\n",
    "    \n",
    "    data_kwargs = {'cluster': eps,\n",
    "                   'clean_floor_num': True,\n",
    "                   'clean_region_city': True,\n",
    "                   'remove_type_0': True,\n",
    "                   'log_target': True,\n",
    "                   'encode_cat': True}\n",
    "    \n",
    "    train_pre, test_pre, num_columns, cat_columns, target = preprocess_data(train, test, **data_kwargs)\n",
    "    X_columns = num_columns + cat_columns\n",
    "    \n",
    "    # If Kfold\n",
    "    #splitter = StratifiedKFold(n_splits=5)\n",
    "    #splits = splitter.split(train_pre, train_pre[\"realty_type\"]) # Stratify by realty type for stability\n",
    "    \n",
    "    # If holdout set\n",
    "    indices = np.arange(train_pre.shape[0])\n",
    "    splits = [train_test_split(indices, test_size=0.2, random_state=42, stratify = train_pre[\"realty_type\"])]\n",
    "    \n",
    "    catboost_params = {'depth': trial.suggest_int('depth', 4, 10), \n",
    "                       'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 1),\n",
    "                       'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 0.1, 100), \n",
    "                       'early_stopping_rounds': trial.suggest_discrete_uniform('early_stopping_rounds', 50, 100, 10)}\n",
    "    \n",
    "    eval_scores = []\n",
    "    iters = []\n",
    "    \n",
    "    for train_index, val_index in splits:\n",
    "        train_split = train_pre.iloc[train_index]\n",
    "        val_split = train_pre.iloc[val_index]\n",
    "        \n",
    "        train_pool = Pool(train_split[X_columns], label = train_split[target], cat_features = cat_columns)\n",
    "        val_pool = Pool(val_split[X_columns], label = val_split[target], cat_features = cat_columns)\n",
    "        \n",
    "        catboost_kwargs = {'use_best_model': False, \n",
    "                   'iterations': 5000,\n",
    "                   'cat_features': cat_columns,\n",
    "                   'eval_metric': UserDefinedMetric(),\n",
    "                   'verbose': 500,\n",
    "                   'subsample': 0.8,\n",
    "                   'colsample_bylevel': 0.8}\n",
    "        \n",
    "        model = CatBoostRegressor(**catboost_kwargs,\n",
    "                                  **catboost_params)\n",
    "        \n",
    "        model.fit(train_pool, eval_set = val_pool)\n",
    "        \n",
    "        # Return loss, iter\n",
    "        eval_scores.append(model.evals_result_[\"validation\"][\"UserDefinedMetric\"][-1])\n",
    "        iters.append(model.tree_count_)\n",
    "        \n",
    "    trial.set_user_attr(\"es_mean_iter\", np.mean(iters))\n",
    "    return np.mean(eval_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cd6aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if hyper_search:\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=20, show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67a959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hyper_search:\n",
    "    print(study.best_params)\n",
    "    print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b739e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hyper_search:\n",
    "    fig = optuna.visualization.plot_optimization_history(study)\n",
    "    fig.show()\n",
    "    \n",
    "    fig = optuna.visualization.plot_param_importances(study)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b14243b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4342815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data_kwargs = {'cluster': 0.0184,\n",
    "               'clean_floor_num': True,\n",
    "               'clean_region_city': True,\n",
    "               'remove_type_0': True,\n",
    "               'log_target': True,\n",
    "               'encode_cat': True}\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "train_pre, test_pre, num_columns, cat_columns, target = preprocess_data(train, test, **data_kwargs)\n",
    "X_columns = num_columns + cat_columns\n",
    "\n",
    "catboost_params = {'depth': 10, \n",
    "                   'learning_rate': 0.015,\n",
    "                   'l2_leaf_reg': 0.5178, \n",
    "                   'early_stopping_rounds': 100}\n",
    "    \n",
    "\n",
    "catboost_kwargs = {'use_best_model': False, \n",
    "                   'iterations': 5000,\n",
    "                   'cat_features': cat_columns,\n",
    "                   'eval_metric': UserDefinedMetric(),\n",
    "                   'verbose': 500,\n",
    "                   'subsample': 0.8,\n",
    "                   'colsample_bylevel': 0.8}\n",
    "\n",
    "if training:\n",
    "    splitter = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)\n",
    "    splits = splitter.split(train_pre, train_pre[\"realty_type\"])\n",
    "    \n",
    "    timestamp = get_timestamp()\n",
    "    \n",
    "    eval_scores = []\n",
    "    feature_importances = []\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(splits):\n",
    "        train_split = train_pre.iloc[train_index]\n",
    "        val_split = train_pre.iloc[val_index]\n",
    "\n",
    "        train_pool = Pool(train_split[X_columns], label = train_split[target], cat_features = cat_columns)\n",
    "        val_pool = Pool(val_split[X_columns], label = val_split[target], cat_features = cat_columns)\n",
    "\n",
    "        model = CatBoostRegressor(**catboost_kwargs,\n",
    "                                  **catboost_params)\n",
    "\n",
    "        model.fit(train_pool, eval_set = val_pool)\n",
    "\n",
    "        model.save_model(f\"models/cb_fold_{i}_{timestamp}.cbm\")\n",
    "\n",
    "        # Return loss, iter\n",
    "        eval_scores.append(model.evals_result_[\"validation\"][\"UserDefinedMetric\"][-1])\n",
    "        feature_importances.append(model.get_feature_importance())\n",
    "\n",
    "    print(\"Avg eval score\", np.mean(eval_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cdfb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating average feature importances\n",
    "if training:\n",
    "    df = pd.DataFrame(feature_importances, columns = X_columns)\n",
    "    df_mean = df.mean(axis=0).sort_values(ascending = True)\n",
    "    df_mean.plot(kind='barh', figsize=(10, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55f929d",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684948da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if inference:\n",
    "    modelnames = [\"cb_fold_0_2021-10-10-11-24.cbm\", \"cb_fold_1_2021-10-10-11-24.cbm\", \"cb_fold_2_2021-10-10-11-24.cbm\", \"cb_fold_3_2021-10-10-11-24.cbm\", \"cb_fold_4_2021-10-10-11-24.cbm\"]\n",
    "    timestamp = get_timestamp()\n",
    "    sample_submission = pd.read_csv('data/test_submission.csv')\n",
    "    predictions = []\n",
    "    \n",
    "    for modelname in modelnames:\n",
    "        model = CatBoostRegressor()\n",
    "        model.load_model(f\"models/{modelname}\")\n",
    "        predictions.append(np.expm1(model.predict(test_pre[X_columns])))\n",
    "        \n",
    "    sample_submission[target] = np.median(np.array(predictions), axis = 0) * 0.94\n",
    "    sample_submission.to_csv(f'submissions/cb_{timestamp}.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}